{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make necessary imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidftransformer vs. Tfidfvectorizer\n",
    "In summary, the main difference between the two modules are as follows:\n",
    "\n",
    "With Tfidftransformer you will systematically compute word counts using CountVectorizer and then compute the Inverse Document Frequency (IDF) values and only then compute the Tf-idf scores.\n",
    "\n",
    "With Tfidfvectorizer on the contrary, you will do all three steps at once. Under the hood, it computes the word counts, IDF values, and Tf-idf scores all using the same dataset.\n",
    "\n",
    "When to use what?\n",
    "So now you may be wondering, why you should use more steps than necessary if you can get everything done in two steps. Well, there are cases where you want to use Tfidftransformer over Tfidfvectorizer and it is sometimes not that obvious. Here is a general guideline:\n",
    "\n",
    "If you need the term frequency (term count) vectors for different tasks, use Tfidftransformer.\n",
    "If you need to compute tf-idf scores on documents within your “training” dataset, use Tfidfvectorizer\n",
    "If you need to compute tf-idf scores on documents outside your “training” dataset, use either one, both will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4869</td>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2909</td>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "5        6903                                        Tehran, USA   \n",
       "6        7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7          95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "8        4869  Fact check: Trump and Clinton at the 'commande...   \n",
       "9        2909  Iran reportedly makes new push for uranium con...   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  \n",
       "5    \\nI’m not an immigrant, but my grandparents ...  FAKE  \n",
       "6  Share This Baylee Luciani (left), Screenshot o...  FAKE  \n",
       "7  A Czech stockbroker who saved more than 650 Je...  REAL  \n",
       "8  Hillary Clinton and Donald Trump made some ina...  REAL  \n",
       "9  Iranian negotiators reportedly have made a las...  REAL  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the DataFrame\n",
    "df = pd.read_csv('C:\\\\Data Science And CS\\\\Fake News Detection Project_1\\\\news.csv')\n",
    "\n",
    "#get head and shape\n",
    "df.shape\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google Pinterest Digg Linkedin Reddit Stumbleupon Print Delicious Pocket Tumblr \\nThere are two fundamental truths in this world: Paul Ryan desperately wants to be president. And Paul Ryan will never be president. Today proved it. \\nIn a particularly staggering example of political cowardice, Paul Ryan re-re-re-reversed course and announced that he was back on the Trump Train after all. This was an aboutface from where he was a few weeks ago. He had previously declared he would not be supporting or defending Trump after a tape was made public in which Trump bragged about assaulting women. Suddenly, Ryan was appearing at a pro-Trump rally and boldly declaring that he already sent in his vote to make him President of the United States. It was a surreal moment. The figurehead of the Republican Party dosed himself in gasoline, got up on a stage on a chilly afternoon in Wisconsin, and lit a match. . @SpeakerRyan says he voted for @realDonaldTrump : “Republicans, it is time to come home” https://t.co/VyTT49YvoE pic.twitter.com/wCvSCg4a5I \\n— ABC News Politics (@ABCPolitics) November 5, 2016 \\nThe Democratic Party couldn’t have asked for a better moment of film. Ryan’s chances of ever becoming president went down to zero in an instant. In the wreckage Trump is to leave behind in his wake, those who cravenly backed his campaign will not recover. If Ryan’s career manages to limp all the way to 2020, then the DNC will have this tape locked and loaded to be used in every ad until Election Day. \\nThe ringing endorsement of the man he clearly hates on a personal level speaks volumes about his own spinelessness. Ryan has postured himself as a “principled” conservative, and one uncomfortable with Trump’s unapologetic bigotry and sexism. However, when push came to shove, Paul Ryan – like many of his colleagues – turned into a sniveling appeaser. After all his lofty tak about conviction, his principles were a house of cards and collapsed with the slightest breeze. \\nWhat’s especially bizarre is how close Ryan came to making it through unscathed. For months the Speaker of the House refused to comment on Trump at all. His strategy seemed to be to keep his head down, pretend Trump didn’t exist, and hope that nobody remembered what happened in 2016. Now, just days away from the election, he screwed it all up. \\nIf 2016’s very ugly election has done any good it’s by exposing the utter cowardice of the Republicans who once feigned moral courage. A reality television star spit on them, hijacked their party, insulted their wives, and got every last one of them to kneel before him. What a turn of events. \\nFeatured image via Twitter'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of a fake news, it is very obvious that the contents are gibberish and makes no sense\n",
    "df['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    FAKE\n",
       "1    FAKE\n",
       "2    REAL\n",
       "3    FAKE\n",
       "4    REAL\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the labels\n",
    "labels = df.label\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting of dataset into training and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF stands for Term Frequency Inverse Document Frequency\n",
    "\n",
    "Algo to transform text into a meaningful representation of numbers to fit ML algo for prediction\n",
    "\n",
    "TF-IDF = TF(t,d) x IDF(t)\n",
    "where:\n",
    "TF = Term frequency (number of times term t, appears in a doc, d)\n",
    "IDF = Inverse Document Frequency (log[(1+n)/(1+df)]) + 1\n",
    "where n = number of documents, df(d,t) = document frequency of the term t\n",
    "\n",
    "stop_words like 'is' will be removed from analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer\n",
      "\n",
      "      00  000  0000  000000031  00000031  0001  0002  000billion  000ft  \\\n",
      "0      0    0     0          0         0     0     0           0      0   \n",
      "1      0    0     0          0         0     0     0           0      0   \n",
      "2      0    0     0          0         0     0     0           0      0   \n",
      "3      0    4     0          0         0     0     0           0      0   \n",
      "4      0    0     0          0         0     0     0           0      0   \n",
      "...   ..  ...   ...        ...       ...   ...   ...         ...    ...   \n",
      "4429   0    0     0          0         0     0     0           0      0   \n",
      "4430   0    0     0          0         0     0     0           0      0   \n",
      "4431   0    0     0          0         0     0     0           0      0   \n",
      "4432   0    0     0          0         0     0     0           0      0   \n",
      "4433   0    0     0          0         0     0     0           0      0   \n",
      "\n",
      "      000km  ...  שתי  תאמצנה  תוצאה  תחל  תיירות  תנותק  תעודת  תתרכז  \\\n",
      "0         0  ...    0       0      0    0       0      0      0      0   \n",
      "1         0  ...    0       0      0    0       0      0      0      0   \n",
      "2         0  ...    0       0      0    0       0      0      0      0   \n",
      "3         0  ...    0       0      0    0       0      0      0      0   \n",
      "4         0  ...    0       0      0    0       0      0      0      0   \n",
      "...     ...  ...  ...     ...    ...  ...     ...    ...    ...    ...   \n",
      "4429      0  ...    0       0      0    0       0      0      0      0   \n",
      "4430      0  ...    0       0      0    0       0      0      0      0   \n",
      "4431      0  ...    0       0      0    0       0      0      0      0   \n",
      "4432      0  ...    0       0      0    0       0      0      0      0   \n",
      "4433      0  ...    0       0      0    0       0      0      0      0   \n",
      "\n",
      "      القادمون  عربي  \n",
      "0            0     0  \n",
      "1            0     0  \n",
      "2            0     0  \n",
      "3            0     0  \n",
      "4            0     0  \n",
      "...        ...   ...  \n",
      "4429         0     0  \n",
      "4430         0     0  \n",
      "4431         0     0  \n",
      "4432         0     0  \n",
      "4433         0     0  \n",
      "\n",
      "[4434 rows x 57841 columns]\n",
      "\n",
      "TFIDF Vectorizer\n",
      "\n",
      "       00       000  0000  000000031  00000031  0001  0002  000billion  000ft  \\\n",
      "0     0.0  0.000000   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
      "1     0.0  0.000000   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
      "2     0.0  0.000000   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
      "3     0.0  0.037913   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
      "4     0.0  0.000000   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
      "...   ...       ...   ...        ...       ...   ...   ...         ...    ...   \n",
      "4429  0.0  0.000000   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
      "4430  0.0  0.000000   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
      "4431  0.0  0.000000   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
      "4432  0.0  0.000000   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
      "4433  0.0  0.000000   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
      "\n",
      "      000km  ...  שתי  תאמצנה  תוצאה  תחל  תיירות  תנותק  תעודת  תתרכז  \\\n",
      "0       0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0   \n",
      "1       0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0   \n",
      "2       0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0   \n",
      "3       0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0   \n",
      "4       0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0   \n",
      "...     ...  ...  ...     ...    ...  ...     ...    ...    ...    ...   \n",
      "4429    0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0   \n",
      "4430    0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0   \n",
      "4431    0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0   \n",
      "4432    0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0   \n",
      "4433    0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0   \n",
      "\n",
      "      القادمون  عربي  \n",
      "0          0.0   0.0  \n",
      "1          0.0   0.0  \n",
      "2          0.0   0.0  \n",
      "3          0.0   0.0  \n",
      "4          0.0   0.0  \n",
      "...        ...   ...  \n",
      "4429       0.0   0.0  \n",
      "4430       0.0   0.0  \n",
      "4431       0.0   0.0  \n",
      "4432       0.0   0.0  \n",
      "4433       0.0   0.0  \n",
      "\n",
      "[4434 rows x 57841 columns]\n"
     ]
    }
   ],
   "source": [
    "#Initialize the TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', max_df = 0.7)\n",
    "#Initiate separate countvectorizer\n",
    "countvectorizer = CountVectorizer(analyzer='word', stop_words = 'english')\n",
    "# instantiate the vectorizer object\n",
    "# use analyzer is word and stop_words is english which are responsible for remove stop words and create word vocabulary\n",
    "\n",
    "#convert the documents into a sparse matrix\n",
    "count_wm = countvectorizer.fit_transform(X_train)\n",
    "tfidf_wm = tfidf.fit_transform(X_train)\n",
    "\n",
    "count_tokens = countvectorizer.get_feature_names()\n",
    "tfidf_tokens = tfidf.get_feature_names()\n",
    "\n",
    "df_countvect = pd.DataFrame(data = count_wm.toarray(), columns = count_tokens)\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(), columns = tfidf_tokens)\n",
    "\n",
    "#CountVectorizer gives number of frequency with respect to index of vocabulary\n",
    "print(\"Count Vectorizer\\n\") \n",
    "print(df_countvect)\n",
    "#TF-IDF considers overall documents of weight of words\n",
    "print(\"\\nTFIDF Vectorizer\\n\")\n",
    "print(df_tfidfvect)\n",
    "\n",
    "#Fit and transform training set and transform test set #TF-IDF\n",
    "tfidf_train = tfidf.fit_transform(X_train)\n",
    "tfidf_test = tfidf.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Matrix form of test data : \n",
      "\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#Fit and transform training set and transform test set #CountVectorizer\n",
    "terms = countvectorizer.fit_transform(X_train)\n",
    "terms_vector = countvectorizer.transform(X_test)\n",
    "\n",
    "print(\"Sparse Matrix form of test data : \\n\")\n",
    "print(terms_vector.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vector of idf \n",
      "\n",
      "[5.7174479  2.63445918 8.55066124 ... 8.55066124 8.55066124 8.55066124]\n",
      "\n",
      "Final tf-idf vectorizer matrix form using 3 steps approach starting from countvectorizer :\n",
      "\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.00823125 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.01490196 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      "Final tf-idf vectorizer matrix form using tf-idfVectorizer :\n",
      "\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.00810119 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.01495287 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      "Both methods should tally.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Transfer sparse matrix of Countvectorizer to TF-IDF by using TFIDF Transformer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_trans = TfidfTransformer(norm ='l2')\n",
    "\n",
    "terms_vector.todense()\n",
    "tfidf_trans.fit(terms_vector)\n",
    "\n",
    "tf_idf_matrix = tfidf_trans.transform(terms_vector)\n",
    "\n",
    "print(\"\\nVector of idf \\n\")\n",
    "print(tfidf_trans.idf_)\n",
    "print(\"\\nFinal tf-idf vectorizer matrix form using 3 steps approach starting from countvectorizer :\\n\")\n",
    "print(tf_idf_matrix.todense())\n",
    "print(\"\\nFinal tf-idf vectorizer matrix form using tf-idfVectorizer :\\n\")\n",
    "print(tfidf_test.todense())\n",
    "print(\"\\nBoth methods should tally.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.53%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.93      0.94      0.94       968\n",
      "        REAL       0.94      0.93      0.93       933\n",
      "\n",
      "    accuracy                           0.94      1901\n",
      "   macro avg       0.94      0.94      0.94      1901\n",
      "weighted avg       0.94      0.94      0.94      1901\n",
      "\n",
      "[[910  58]\n",
      " [ 65 868]]\n"
     ]
    }
   ],
   "source": [
    "#Initialize a PassiveAggressiveClassifier\n",
    "pac = PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(tfidf_train,y_train)\n",
    "\n",
    "#Predict on the test set and calculate accuracy\n",
    "y_pred = pac.predict(tfidf_test)\n",
    "score = accuracy_score(y_test,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred, labels=['FAKE','REAL']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
